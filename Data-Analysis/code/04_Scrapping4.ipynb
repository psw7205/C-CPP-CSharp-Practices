{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lxml 사용 기초 스크랩핑\n",
    "\n",
    "- 네이버 메인의 신문사 url 갖고 옴 => xpath 사용\n",
    "- session을 사용하면 서버에서 일정 시간동안 연결된 정보를 사용할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml.html import fromstring, tostring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_news_list_page(response):\n",
    "    # URL 딕셔너리 선언\n",
    "    urls = {}\n",
    "    # 태그 정보 문자열 저장\n",
    "    root = fromstring(response.content)\n",
    "\n",
    "    # 문서내 경로 절대 경로 변환\n",
    "    root.make_links_absolute(response.url)\n",
    "    \n",
    "    # //*[@id=\"NS_032\"]\n",
    "    for a in root.xpath('//ul[@class=\"api_list\"]' \\\n",
    "    '/li[@class=\"api_item\"]/a[@class=\"api_link\"]'):\n",
    "    \n",
    "        # 신문사, 링크 추출 함수\n",
    "        name, url = extract_contents(a)\n",
    "\n",
    "        # 딕셔너리 삽입\n",
    "        urls[name] = url\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contents(dom):\n",
    "    # 링크 주소\n",
    "    link = dom.get('href')\n",
    "    \n",
    "    # 신문사 명 \n",
    "    # dom.xpath()는 리스트로 반환  //*[@id=\"NS_139\"]/a/img\n",
    "    name = dom.xpath('./img')[0].get('alt')\n",
    "    return name, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시사인 http://newsstand.naver.com/?list=ct1&pcode=308\n",
      "노컷뉴스 http://newsstand.naver.com/?list=ct1&pcode=079\n",
      "문화일보 http://newsstand.naver.com/?list=ct1&pcode=021\n",
      "KBS World http://newsstand.naver.com/?list=ct1&pcode=326\n",
      "아시아경제 http://newsstand.naver.com/?list=ct1&pcode=277\n",
      "뉴스타파 http://newsstand.naver.com/?list=ct1&pcode=930\n",
      "지지통신 http://newsstand.naver.com/?list=ct1&pcode=376\n",
      "서울경제 http://newsstand.naver.com/?list=ct1&pcode=011\n",
      "뉴데일리 http://newsstand.naver.com/?list=ct1&pcode=327\n",
      "경향신문 http://newsstand.naver.com/?list=ct1&pcode=032\n",
      "중앙일보 http://newsstand.naver.com/?list=ct1&pcode=025\n",
      "MBC http://newsstand.naver.com/?list=ct1&pcode=214\n",
      "소년한국일보 http://newsstand.naver.com/?list=ct7&pcode=329\n",
      "TBC대구방송 http://newsstand.naver.com/?list=ct3&pcode=989\n",
      "시사저널 http://newsstand.naver.com/?list=ct7&pcode=135\n",
      "조세일보 http://newsstand.naver.com/?list=ct2&pcode=123\n",
      "철강금속신문 http://newsstand.naver.com/?list=ct7&pcode=956\n",
      "한경비즈니스 http://newsstand.naver.com/?list=ct7&pcode=050\n"
     ]
    }
   ],
   "source": [
    "# 세션 사용\n",
    "session = requests.Session()\n",
    "# 스크랩핑 대상 URL\n",
    "response = session.get('http://www.naver.com/')\n",
    "# 신문사 정보 딕셔너리 획득\n",
    "urls = scrape_news_list_page(response)\n",
    "# 딕셔너리 확인\n",
    "# print(urls)\n",
    "# 결과 출력\n",
    "for name, url in urls.items():\n",
    "    print(name, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
